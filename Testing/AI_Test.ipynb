{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Test.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH904AFxSiZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### required\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqRIHtHVTYlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### required\n",
        "!pip install configparser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHFGzyxyUmFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### required\n",
        "!pip install keras==1.2.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aza8nqNxSwU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD ,Adagrad\n",
        "from scipy.io import loadmat, savemat\n",
        "from keras.models import model_from_json\n",
        "import theano.tensor as T\n",
        "import theano\n",
        "import csv\n",
        "import configparser\n",
        "import collections\n",
        "import time\n",
        "import os\n",
        "import skimage.transform\n",
        "from skimage import color\n",
        "import numpy as np\n",
        "import numpy as numpy\n",
        "from datetime import datetime\n",
        "from scipy.spatial.distance import cdist,pdist,squareform\n",
        "import shutil\n",
        "\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE_xKWUb6yj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(json_path):  # Function to load the model\n",
        "    model = model_from_json(open(json_path).read())\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA092ZZK619g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_dict(dict2):\n",
        "    i = 0\n",
        "    dict = {}\n",
        "    for i in range(len(dict2)):\n",
        "        if str(i) in dict2:\n",
        "            if dict2[str(i)].shape == (0, 0):\n",
        "                dict[str(i)] = dict2[str(i)]\n",
        "            else:\n",
        "                weights = dict2[str(i)][0]\n",
        "                weights2 = []\n",
        "                for weight in weights:\n",
        "                    if weight.shape in [(1, x) for x in range(0, 5000)]:\n",
        "                        weights2.append(weight[0])\n",
        "                    else:\n",
        "                        weights2.append(weight)\n",
        "                dict[str(i)] = weights2\n",
        "    return dict\n",
        "\n",
        "def load_weights(model, weight_path):\n",
        "    dict2 = loadmat(weight_path)\n",
        "    dict = conv_dict(dict2)\n",
        "    i = 0\n",
        "    for layer in model.layers:\n",
        "        weights = dict[str(i)]\n",
        "        layer.set_weights(weights)\n",
        "        i += 1\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omxIzwxeTDsy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset_One_Video_Features(Test_Video_Path):\n",
        "    VideoPath =Test_Video_Path\n",
        "    f = open(VideoPath, \"r\")\n",
        "    words = f.read().split()\n",
        "    num_feat = len(words) / 4096\n",
        "    \n",
        "    count = -1;\n",
        "    VideoFeatues = []\n",
        "    for feat in range(0, int(num_feat)):\n",
        "        feat_row1 = np.float32(words[feat * 4096:feat * 4096 + 4096])\n",
        "        count = count + 1\n",
        "        if count == 0:\n",
        "            VideoFeatues = feat_row1\n",
        "        if count > 0:\n",
        "            VideoFeatues = np.vstack((VideoFeatues, feat_row1))\n",
        "    AllFeatures = VideoFeatues\n",
        "\n",
        "    return  AllFeatures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WuwK4mf-W2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AllTest_Video_Path = '/content/drive/My Drive/C3D/C3D-v1.0/examples/c3d_feature_extraction/out'\n",
        "Results_Path = '/result/'\n",
        "Model_dir='/content/drive/My Drive/C3D/C3D-v1.0/examples/c3d_feature_extraction/out/'\n",
        "\n",
        "weights_path = Model_dir + 'weights_L1L2.mat'\n",
        "model_path = Model_dir + 'model.json'\n",
        "\n",
        "if not os.path.exists(Results_Path):\n",
        "       os.makedirs(Results_Path)\n",
        "\n",
        "with open(AllTest_Video_Path+\"/test.txt\", 'r') as f1:\n",
        "    for line in f1:\n",
        "       All_Test_files.append(line.strip())\n",
        "\n",
        "with open(AllTest_Video_Path+\"/label.txt\", 'r') as f1:\n",
        "      for line in f1:\n",
        "          Label.append(line.strip())\n",
        "\n",
        "model=load_model(model_path)\n",
        "load_weights(model, weights_path)\n",
        "nVideos=len(All_Test_files)\n",
        "time_before = datetime.now()\n",
        "\n",
        "accuracy=0\n",
        "count=0\n",
        "for iv in range(nVideos):\n",
        "    Test_Video_Path = os.path.join(AllTest_Video_Path, All_Test_files[iv])\n",
        "    inputs=load_dataset_One_Video_Features(Test_Video_Path)\n",
        "    predictions = model.predict_on_batch(inputs)\n",
        "    aa=All_Test_files[iv]\n",
        "    aa=aa[0:-4]\n",
        "    if(Label[iv]==1 and int(max(predictions))>0): \n",
        "      accuracy+=1\n",
        "    elif (Label[iv]==0 and int(max(predictions))==0):\n",
        "      accuracy+=1\n",
        "    count+=1\n",
        "    \n",
        "print(\"Accuracy : \" +str(accuracy/count))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}